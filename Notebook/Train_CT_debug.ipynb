{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baf3bed-1ce1-49a7-bf0f-7d2990534621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep data\n",
      "Prep model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep optimizer\n",
      "59000161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mql2221\u001b[0m (\u001b[33mqiliu2221\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/ql2221/thermalizer_data/wandb_data/wandb/run-20250715_164800-lz0z0z1i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qiliu2221/thermalizer/runs/lz0z0z1i' target=\"_blank\">-f</a></strong> to <a href='https://wandb.ai/qiliu2221/thermalizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qiliu2221/thermalizer' target=\"_blank\">https://wandb.ai/qiliu2221/thermalizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qiliu2221/thermalizer/runs/lz0z0z1i' target=\"_blank\">https://wandb.ai/qiliu2221/thermalizer/runs/lz0z0z1i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at epoch 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m trainer = Train_CT.CTR_Trainer(config)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(trainer.config[\u001b[33m\"\u001b[39m\u001b[33mcnn learnable parameters\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/Training/Train_conditional_thermalizer_algo.py:458\u001b[39m, in \u001b[36mCTR_Trainer.run\u001b[39m\u001b[34m(self, epochs)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28mself\u001b[39m.epoch=epoch\n\u001b[32m    457\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining at epoch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.epoch)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28mself\u001b[39m.valid_loop()\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.save_checkpoint(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33msave_path\u001b[39m\u001b[33m\"\u001b[39m]+\u001b[33m\"\u001b[39m\u001b[33m/checkpoint_last.p\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/Training/Train_conditional_thermalizer_algo.py:360\u001b[39m, in \u001b[36mCTR_Trainer.training_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    357\u001b[39m noise = noise.to(\u001b[38;5;28mself\u001b[39m.gpu_id)  \u001b[38;5;66;03m# Move to GPU\u001b[39;00m\n\u001b[32m    359\u001b[39m delta = torch.randint(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mlagsteps\u001b[39m\u001b[33m\"\u001b[39m]-\u001b[32m1\u001b[39m, (\u001b[32m1\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m pred_noise, t, pred_noise_level = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m noise = noise[:,-\u001b[32m1\u001b[39m:]\n\u001b[32m    363\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(pred_noise,noise)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/Models/diffusion_regression.py:80\u001b[39m, in \u001b[36mDiffusion_regression.forward\u001b[39m\u001b[34m(self, x, noise, delta, predict_noise_level)\u001b[39m\n\u001b[32m     78\u001b[39m x_t_minus = torch.zeros_like(x_t)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x)):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     x_t_minus[i] = \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m-\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m#concatenate the vectors so that they can be fed into the neural net\u001b[39;00m\n\u001b[32m     83\u001b[39m x_noised_plus_x_t_minus = torch.cat((x_t_noised, x_t_minus), dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import sys\n",
    "import Training.Train_conditional_thermalizer_algo as Train_CT\n",
    "import Models.misc as misc\n",
    "\n",
    "\n",
    "## Stop jax hoovering up GPU memory\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "config={}\n",
    "config[\"input_channels\"]=2\n",
    "config[\"output_channels\"]=1\n",
    "config[\"model_type\"]=\"ModernUnetRegressor\"\n",
    "config[\"dim_mults\"]=[2,2,2] \n",
    "config[\"hidden_channels\"]=64\n",
    "config[\"activation\"]=\"gelu\"\n",
    "config[\"loader_workers\"]=1\n",
    "config[\"image_size\"]=64\n",
    "\n",
    "#how many steps do we allow ourselves to look to the past\n",
    "config[\"timesteps\"] = 1000\n",
    "config[\"lagsteps\"] = 128\n",
    "\n",
    "config[\"lag_embedding\"] = 512\n",
    "#config[\"noise_timestep_embedding\"] = 512\n",
    "\n",
    "config[\"project\"]=\"thermalizer\"\n",
    "config[\"regression_loss_weight\"] = 0.5\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    wandb_run_name = sys.argv[1]  # take the first argument\n",
    "else:\n",
    "    wandb_run_name = misc.rs()\n",
    "config[\"wandb_run_name\"] = wandb_run_name\n",
    "config[\"norm\"]=False\n",
    "config[\"ddp\"]=False\n",
    "config[\"PDE\"]=\"Kolmogorov\"\n",
    "config[\"file_path\"]=\"/scratch/ql2221/thermalizer_data/kolmogorov/reynold10k/test.p\"\n",
    "config[\"save_path\"]=\"/scratch/ql2221/thermalizer_data/wandb_data\"\n",
    "config[\"subsample\"]=None\n",
    "config[\"train_ratio\"]=0.95\n",
    "config[\"save_name\"]=\"model_weights.pt\"\n",
    "\n",
    "config[\"optimization\"]={}\n",
    "config[\"optimization\"][\"epochs\"]=200\n",
    "config[\"optimization\"][\"lr\"]=0.0002\n",
    "config[\"optimization\"][\"wd\"]=0.05\n",
    "config[\"optimization\"][\"batch_size\"]=64\n",
    "config[\"optimization\"][\"gradient_clipping\"]=1.\n",
    "config[\"optimization\"][\"scheduler_step\"]=100000\n",
    "config[\"optimization\"][\"scheduler_gamma\"]=0.5\n",
    "\n",
    "#if training from checkpoint uncomment this\n",
    "# checkpoint_string = \"/scratch/ql2221/thermalizer_data/wandb_data/wandb/run-20250521_134541-z6d1vc7f/files/checkpoint_last.p\"\n",
    "# trainer = Train_Unet.trainer_from_checkpoint(checkpoint_string)\n",
    "# trainer.config[\"optimization\"][\"epochs\"]= config[\"optimization\"][\"epochs\"]\n",
    "\n",
    "trainer = Train_CT.CTR_Trainer(config)\n",
    "print(trainer.config[\"cnn learnable parameters\"])\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39494c93-ddd1-4c87-841b-cc597a3053e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_sing",
   "language": "python",
   "name": "torch_sing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
