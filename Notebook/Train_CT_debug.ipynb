{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2baf3bed-1ce1-49a7-bf0f-7d2990534621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep data\n",
      "Prep model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep optimizer\n",
      "59000161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mql2221\u001b[0m (\u001b[33mqiliu2221\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/ql2221/thermalizer_data/wandb_data/wandb/run-20250715_181402-e53wgu4l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qiliu2221/thermalizer/runs/e53wgu4l' target=\"_blank\">-f</a></strong> to <a href='https://wandb.ai/qiliu2221/thermalizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qiliu2221/thermalizer' target=\"_blank\">https://wandb.ai/qiliu2221/thermalizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qiliu2221/thermalizer/runs/e53wgu4l' target=\"_blank\">https://wandb.ai/qiliu2221/thermalizer/runs/e53wgu4l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at epoch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m trainer = Train_CT.CTR_Trainer(config)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(trainer.config[\u001b[33m\"\u001b[39m\u001b[33mcnn learnable parameters\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/Training/Train_conditional_thermalizer_algo.py:458\u001b[39m, in \u001b[36mCTR_Trainer.run\u001b[39m\u001b[34m(self, epochs)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28mself\u001b[39m.epoch=epoch\n\u001b[32m    457\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining at epoch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.epoch)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28mself\u001b[39m.valid_loop()\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.save_checkpoint(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33msave_path\u001b[39m\u001b[33m\"\u001b[39m]+\u001b[33m\"\u001b[39m\u001b[33m/checkpoint_last.p\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/lib/python3.12/site-packages/Training/Train_conditional_thermalizer_algo.py:360\u001b[39m, in \u001b[36mCTR_Trainer.training_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    357\u001b[39m noise = noise.to(\u001b[38;5;28mself\u001b[39m.gpu_id)  \u001b[38;5;66;03m# Move to GPU\u001b[39;00m\n\u001b[32m    359\u001b[39m delta = torch.randint(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mlagsteps\u001b[39m\u001b[33m\"\u001b[39m]-\u001b[32m1\u001b[39m, (\u001b[32m1\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m pred_noise, t, pred_noise_level = \u001b[38;5;28mself\u001b[39m.model(image,noise,delta.item(),\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    362\u001b[39m noise = noise[:,-\u001b[32m1\u001b[39m:]\n\u001b[32m    363\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(pred_noise,noise)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import sys\n",
    "import Training.Train_conditional_thermalizer_algo as Train_CT\n",
    "import Models.misc as misc\n",
    "\n",
    "\n",
    "## Stop jax hoovering up GPU memory\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "config={}\n",
    "config[\"input_channels\"]=2\n",
    "config[\"output_channels\"]=1\n",
    "config[\"model_type\"]=\"ModernUnetRegressor\"\n",
    "config[\"dim_mults\"]=[2,2,2] \n",
    "config[\"hidden_channels\"]=64\n",
    "config[\"activation\"]=\"gelu\"\n",
    "config[\"loader_workers\"]=1\n",
    "config[\"image_size\"]=64\n",
    "\n",
    "#how many steps do we allow ourselves to look to the past\n",
    "config[\"timesteps\"] = 1000\n",
    "config[\"lagsteps\"] = 128\n",
    "\n",
    "config[\"lag_embedding\"] = 512\n",
    "#config[\"noise_timestep_embedding\"] = 512\n",
    "\n",
    "config[\"project\"]=\"thermalizer\"\n",
    "config[\"regression_loss_weight\"] = 0.5\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    wandb_run_name = sys.argv[1]  # take the first argument\n",
    "else:\n",
    "    wandb_run_name = misc.rs()\n",
    "config[\"wandb_run_name\"] = wandb_run_name\n",
    "config[\"norm\"]=False\n",
    "config[\"ddp\"]=False\n",
    "config[\"PDE\"]=\"Kolmogorov\"\n",
    "config[\"file_path\"]=\"/scratch/ql2221/thermalizer_data/kolmogorov/reynold10k/test.p\"\n",
    "config[\"save_path\"]=\"/scratch/ql2221/thermalizer_data/wandb_data\"\n",
    "config[\"subsample\"]=None\n",
    "config[\"train_ratio\"]=0.95\n",
    "config[\"save_name\"]=\"model_weights.pt\"\n",
    "\n",
    "config[\"optimization\"]={}\n",
    "config[\"optimization\"][\"epochs\"]=200\n",
    "config[\"optimization\"][\"lr\"]=0.0002\n",
    "config[\"optimization\"][\"wd\"]=0.05\n",
    "config[\"optimization\"][\"batch_size\"]=64\n",
    "config[\"optimization\"][\"gradient_clipping\"]=1.\n",
    "config[\"optimization\"][\"scheduler_step\"]=100000\n",
    "config[\"optimization\"][\"scheduler_gamma\"]=0.5\n",
    "\n",
    "#if training from checkpoint uncomment this\n",
    "# checkpoint_string = \"/scratch/ql2221/thermalizer_data/wandb_data/wandb/run-20250521_134541-z6d1vc7f/files/checkpoint_last.p\"\n",
    "# trainer = Train_Unet.trainer_from_checkpoint(checkpoint_string)\n",
    "# trainer.config[\"optimization\"][\"epochs\"]= config[\"optimization\"][\"epochs\"]\n",
    "\n",
    "trainer = Train_CT.CTR_Trainer(config)\n",
    "print(trainer.config[\"cnn learnable parameters\"])\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39494c93-ddd1-4c87-841b-cc597a3053e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 128, 64, 64])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"/scratch/ql2221/thermalizer_data/kolmogorov/reynold10k/test.p\")\n",
    "data[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5923fb7-8f5f-4d1e-96fe-318652ee4c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_sing",
   "language": "python",
   "name": "torch_sing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
